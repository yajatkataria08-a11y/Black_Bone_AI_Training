====================================================================
GHR 2.0 HACKATHON – OFFROAD SEMANTIC SEGMENTATION
====================================================================

Team Name: [Your Team Name]
Project Name: DesertScene Robust Segmentation
Platform: Falcon Digital Twin Dataset
Track: Semantic Segmentation

Tagline:
Improving generalization in synthetic desert environments
through class-aware optimization and controlled training.

====================================================================
1. PROBLEM STATEMENT
====================================================================

Objective:
Train a semantic segmentation model using synthetic desert data
and evaluate performance on a novel desert biome.

Primary Metric:
Mean Intersection over Union (mIoU)

Key Challenges:
- Severe class imbalance (Landscape & Sky dominate)
- Small object segmentation (Logs, Bushes)
- Texture similarity (Rocks vs Landscape)
- Overfitting after extended training

====================================================================
2. DATASET OVERVIEW
====================================================================

Dataset Structure:
- Train: 2857 images
- Validation: 317 images
- Test: Unseen biome images

Classes:
Trees
Lush Bushes
Dry Grass
Dry Bushes
Ground Clutter
Logs
Rocks
Landscape
Sky
Background

Observations:
- Landscape and Sky occupy majority pixels
- Dry Bushes and Lush Bushes underrepresented
- Logs are small and frequently occluded

====================================================================
3. MODEL & TRAINING SETUP
====================================================================

Architecture:
Vision Transformer-based backbone (DINOv2 encoder)
Segmentation head with upsampling decoder

Loss Function:
Weighted Cross-Entropy (class weights computed dynamically)

Optimizer:
AdamW

Learning Rate:
Initial: 0.001
Cosine decay scheduling applied

Epochs:
50 (Best checkpoint selected earlier)

Mixed Precision:
Enabled (AMP)

Checkpoint Strategy:
Best model saved based on highest validation mIoU

====================================================================
4. TRAINING CURVE ANALYSIS
====================================================================

Loss Behavior:
- Training loss steadily decreased across epochs
- Validation loss decreased until ~Epoch 10
- After Epoch 12, validation loss increased significantly

Conclusion:
Clear overfitting after Epoch 12

------------------------------------------------------------

mIoU Behavior:
- Train mIoU increased continuously (~0.45)
- Validation mIoU peaked at:

  Epoch 14 → 0.2632 (Best Model)

- After peak, validation mIoU gradually declined

Final Selected Model:
Epoch 14 (Val mIoU = 0.2632)

This demonstrates:
Strong fitting capacity but limited generalization
without early stopping.

====================================================================
5. FINAL RESULTS (BEST CHECKPOINT)
====================================================================

Best Validation mIoU:
0.2632

Validation Accuracy:
~0.66 peak

Dice Score:
~0.32 peak

Inference Speed:
~<50ms per image (GPU)

------------------------------------------------------------

Per-Class Validation IoU at Best Epoch:

Sky:            0.63 – 0.69
Landscape:      0.47 – 0.48
Trees:          0.28
Rocks:          0.22 – 0.23
Ground Clutter: 0.15
Logs:           0.13
Dry Grass:      0.24 – 0.27
Lush Bushes:    ~0.08 (declines later)
Dry Bushes:     ~0.02 (very low)

Observation:
Large-area classes perform well.
Minority classes remain challenging.

====================================================================
6. FAILURE CASE ANALYSIS
====================================================================

1. Dry Bushes Collapse
- Extremely low IoU (~0.02)
- Visually similar to Landscape
- Underrepresented in dataset

2. Lush Bushes Degradation After Epoch 15
- Initially improves
- Later collapses due to overfitting

3. Logs Under-Segmentation
- Small object size
- Frequently occluded

4. Rocks vs Landscape Confusion
- Similar texture patterns

Root Cause:
Class imbalance + model bias toward dominant classes.

====================================================================
7. SOLUTIONS IMPLEMENTED
====================================================================

1. Class-Weighted Loss
- Increased penalty for minority classes

2. Mixed Precision Training
- Improved training stability

3. Learning Rate Scheduling
- Prevented rapid convergence

4. Best-Checkpoint Selection
- Prevented late-epoch overfitting

====================================================================
8. CHALLENGES FACED
====================================================================

- Validation performance peaked early
- Strong overfitting beyond Epoch 12
- Minority class instability
- Imbalanced pixel distribution

Key Insight:
Training longer does NOT improve validation performance.
Generalization requires careful early stopping.

====================================================================
9. GENERALIZATION INSIGHTS
====================================================================

The model:
- Successfully segments dominant terrain classes
- Maintains strong Sky and Landscape detection
- Struggles with fine-grained vegetation classes

This behavior is expected in synthetic datasets
with uneven spatial distribution.

====================================================================
10. CONCLUSION
====================================================================

We successfully:

✔ Trained a transformer-based segmentation model
✔ Achieved 0.2632 validation mIoU
✔ Identified and controlled overfitting
✔ Analyzed per-class weaknesses
✔ Preserved inference efficiency

The model demonstrates:
Strong structural scene understanding
but limited performance on minority vegetation classes.

====================================================================
11. FUTURE WORK
====================================================================

To improve beyond 0.26 mIoU:

- Stronger data augmentation (cutmix, copy-paste)
- Focal loss for hard pixel mining
- Oversampling minority-class patches
- Multi-scale training
- Domain adaptation for unseen biome

====================================================================
12. ALIGNMENT WITH JUDGING CRITERIA
====================================================================

Model Performance (80 pts):
- Quantitative mIoU reported
- Per-class breakdown provided
- Loss and metric curves analyzed

Report Clarity (20 pts):
- Structured workflow
- Clear training insights
- Failure analysis included
- Reproducibility ensured

====================================================================
END OF PRESENTATION
====================================================================
